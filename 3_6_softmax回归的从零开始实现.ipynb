{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/O8LVAAhE2lx75M8Vn2QV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieldai/Dive-into-DL-PyTorch-in-Colab/blob/main/3_6_softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.6_softmax-regression-scratch"
      ],
      "metadata": {
        "id": "5QFLqiQYVIfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "下载 d2lzh_pytorch 到colab环境中"
      ],
      "metadata": {
        "id": "0KWbVaa0kKxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShusenTang/Dive-into-DL-PyTorch.git\n",
        "#!ls Dive-into-DL-PyTorch/code/d2lzh_pytorch\n",
        "!cp -r Dive-into-DL-PyTorch/code/d2lzh_pytorch /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE5DoPZ7Vgdb",
        "outputId": "3c60574d-41b6-46dd-fe7b-b2422d6557d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dive-into-DL-PyTorch'...\n",
            "remote: Enumerating objects: 1822, done.\u001b[K\n",
            "remote: Total 1822 (delta 0), reused 0 (delta 0), pack-reused 1822\u001b[K\n",
            "Receiving objects: 100% (1822/1822), 34.33 MiB | 17.07 MiB/s, done.\n",
            "Resolving deltas: 100% (1058/1058), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.6 softmax回归的从零开始实现\n",
        "\n",
        "这一节我们来动手实现softmax回归。首先导入本节实现所需的包或模块。"
      ],
      "metadata": {
        "id": "OwPD3-xEkGCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "torchtext.disable_torchtext_deprecation_warning()\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import sys\n",
        "sys.path.append(\"..\") # 为了导入上层目录的d2lzh_pytorch\n",
        "import d2lzh_pytorch as d2l\n",
        "\n"
      ],
      "metadata": {
        "id": "fzRu8WkUVndZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6.1 获取和读取数据\n",
        "\n",
        "我们将使用Fashion-MNIST数据集，并设置批量大小为256。"
      ],
      "metadata": {
        "id": "r8zBg9AQjr6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root='/content/Datasets/FashionMNIS')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2-SzSjwVuRX",
        "outputId": "7f93c62d-e05b-4d02-b566-85f049b47247"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11393501.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/Datasets/FashionMNIS/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 190853.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/Datasets/FashionMNIS/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3647137.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/Datasets/FashionMNIS/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 18267577.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/Datasets/FashionMNIS/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/Datasets/FashionMNIS/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6.2 初始化模型参数\n",
        "跟线性回归中的例子一样，我们将使用向量表示每个样本。已知每个样本输入是高和宽均为28像素的图像。模型的输入向量的长度是 $28 \\times 28 = 784$：该向量的每个元素对应图像中每个像素。由于图像有10个类别，单层神经网络输出层的输出个数为10，因此softmax回归的权重和偏差参数分别为$784 \\times 10$和$1 \\times 10$的矩阵。"
      ],
      "metadata": {
        "id": "Y9zM4TOBkjRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "\n",
        "W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype=torch.float)\n",
        "b = torch.zeros(num_outputs, dtype=torch.float)\n"
      ],
      "metadata": {
        "id": "iogov7QQV-W6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "同之前一样，我们需要模型参数梯度。"
      ],
      "metadata": {
        "id": "OwE3ZsKdlapc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W.requires_grad_(requires_grad=True)\n",
        "b.requires_grad_(requires_grad=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDfdD97zWETb",
        "outputId": "fd9d8274-60be-4c42-b4f3-bee6d56a563e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6.3 实现softmax运算\n",
        "\n",
        "在介绍如何定义softmax回归之前，我们先描述一下对如何对多维`Tensor`按维度操作。在下面的例子中，给定一个`Tensor`矩阵`X`。我们可以只对其中同一列（`dim=0`）或同一行（`dim=1`）的元素求和，并在结果中保留行和列这两个维度（`keepdim=True`）。"
      ],
      "metadata": {
        "id": "r6c11naulgEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(X.sum(dim=0, keepdim=True))\n",
        "print(X.sum(dim=1, keepdim=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cP5CS3Olwfb",
        "outputId": "e5ee0327-6f43-4102-aed6-7be4704dc050"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 7, 9]])\n",
            "tensor([[ 6],\n",
            "        [15]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "下面我们就可以定义前面小节里介绍的softmax运算了。在下面的函数中，矩阵`X`的行数是样本数，列数是输出个数。为了表达样本预测各个输出的概率，softmax运算会先通过`exp`函数对每个元素做指数运算，再对`exp`矩阵同行元素求和，最后令矩阵每行各元素与该行元素之和相除。这样一来，最终得到的矩阵每行元素和为1且非负。因此，该矩阵每行都是合法的概率分布。softmax运算的输出矩阵中的任意一行元素代表了一个样本在各个输出类别上的预测概率。"
      ],
      "metadata": {
        "id": "hnrSoP4El62Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(X):\n",
        "    X_exp = X.exp()\n",
        "    partition = X_exp.sum(dim=1, keepdim=True)\n",
        "    return X_exp / partition  # 这里应用了广播机制\n"
      ],
      "metadata": {
        "id": "ppNB-BpwWLYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def net(X):\n",
        "    return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)\n"
      ],
      "metadata": {
        "id": "rIAoLOqtWQeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
        "y = torch.LongTensor([0, 2])\n",
        "y_hat.gather(1, y.view(-1, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lJ7e5IFWTHJ",
        "outputId": "f39ac854-878a-447c-c6e8-b394fd01f8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1000],\n",
              "        [0.5000]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(y_hat, y):\n",
        "    return - torch.log(y_hat.gather(1, y.view(-1, 1)))\n"
      ],
      "metadata": {
        "id": "qaQ2eLVrWWml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_hat, y):\n",
        "    return (y_hat.argmax(dim=1) == y).float().mean().item()\n"
      ],
      "metadata": {
        "id": "BBEngeC-WZu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进：它的完整实现将在“图像增广”一节中描述\n",
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0.0, 0\n",
        "    for X, y in data_iter:\n",
        "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
        "        n += y.shape[0]\n",
        "    return acc_sum / n\n"
      ],
      "metadata": {
        "id": "8D3c426GWdSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs, lr = 5, 0.1\n",
        "\n",
        "# 本函数已保存在d2lzh包中方便以后使用\n",
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
        "              params=None, lr=None, optimizer=None):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
        "        for X, y in train_iter:\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y).sum()\n",
        "\n",
        "            # 梯度清零\n",
        "            if optimizer is not None:\n",
        "                optimizer.zero_grad()\n",
        "            elif params is not None and params[0].grad is not None:\n",
        "                for param in params:\n",
        "                    param.grad.data.zero_()\n",
        "\n",
        "            l.backward()\n",
        "            if optimizer is None:\n",
        "                d2l.sgd(params, lr, batch_size)\n",
        "            else:\n",
        "                optimizer.step()  # “softmax回归的简洁实现”一节将用到\n",
        "\n",
        "\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "            n += y.shape[0]\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
        "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
        "\n",
        "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txMceQVOWhG9",
        "outputId": "6cb5e1ba-6230-4f22-aa2e-8b7fc180d7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.7840, train acc 0.748, test acc 0.791\n",
            "epoch 2, loss 0.5708, train acc 0.812, test acc 0.811\n",
            "epoch 3, loss 0.5257, train acc 0.826, test acc 0.815\n",
            "epoch 4, loss 0.5018, train acc 0.832, test acc 0.824\n",
            "epoch 5, loss 0.4858, train acc 0.836, test acc 0.829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = iter(test_iter).next()\n",
        "\n",
        "true_labels = d2l.get_fashion_mnist_labels(y.numpy())\n",
        "pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(dim=1).numpy())\n",
        "titles = [true + '\\n' + pred for true, pred in zip(true_labels, pred_labels)]\n",
        "\n",
        "d2l.show_fashion_mnist(X[0:9], titles[0:9])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1We9zUIHWzYs",
        "outputId": "d57e8144-baab-4f4c-e67a-0eaea579ad49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6d43c8fd6a29>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fashion_mnist_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fashion_mnist_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ]
    }
  ]
}